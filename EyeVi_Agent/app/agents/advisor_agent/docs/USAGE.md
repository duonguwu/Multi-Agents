# H∆∞·ªõng d·∫´n S·ª≠ d·ª•ng PDF RAG System

## üèóÔ∏è Ki·∫øn tr√∫c M·ªõi (T√°ch bi·ªát + Data Folder)

H·ªá th·ªëng ƒë∆∞·ª£c t√°ch th√†nh 2 ph·∫ßn ch√≠nh v·ªõi th∆∞ m·ª•c `data/` m·∫∑c ƒë·ªãnh:

1. **üì• Data Ingestion** (`ingest_data.py`) - Script n·∫°p d·ªØ li·ªáu t·ª´ `data/` (ch·∫°y 1 l·∫ßn)
2. **ü§ñ Chatbot** (`chatbot.py`) - Class x·ª≠ l√Ω queries (invoke m·ªói l·∫ßn chat)

## üöÄ Quy tr√¨nh S·ª≠ d·ª•ng (ƒê∆°n gi·∫£n h√≥a)

### B∆∞·ªõc 1: Chu·∫©n b·ªã M√¥i tr∆∞·ªùng

```bash
# 1. C√†i ƒë·∫∑t dependencies
pip install -r requirements.txt

# 2. Kh·ªüi ƒë·ªông Qdrant server
docker-compose up -d

# 3. C·∫•u h√¨nh Google API key
export GOOGLE_API_KEY="your_google_api_key_here"
```

### B∆∞·ªõc 2: Setup Data Folder

```bash
# T·∫°o th∆∞ m·ª•c data (n·∫øu ch∆∞a c√≥)
mkdir data

# ƒê·∫∑t PDF files v√†o data/
cp your_files.pdf data/
# Ho·∫∑c t·∫°o subfolder
mkdir data/research && cp research_papers.pdf data/research/
```

### B∆∞·ªõc 3: N·∫°p D·ªØ li·ªáu PDF (m·ªôt l·∫ßn)

```bash
# N·∫°p t·ª´ th∆∞ m·ª•c data/ (m·∫∑c ƒë·ªãnh)
python ingest_data.py

# Ho·∫∑c v·ªõi options
python ingest_data.py --clear     # X√≥a d·ªØ li·ªáu c≈©
python ingest_data.py --check     # Ki·ªÉm tra tr·∫°ng th√°i
```

### B∆∞·ªõc 4: S·ª≠ d·ª•ng Chatbot

```bash
# Setup guide (l·∫ßn ƒë·∫ßu)
python main.py setup

# Demo chatbot
python main.py demo

# Ch·∫ø ƒë·ªô t∆∞∆°ng t√°c
python main.py interactive

# Ki·ªÉm tra tr·∫°ng th√°i
python main.py check
```

## üìú Chi ti·∫øt Commands

### üîß Data Ingestion Script

```bash
python ingest_data.py [options]
```

**M·∫∑c ƒë·ªãnh**: T·ª± ƒë·ªông n·∫°p t·ª´ th∆∞ m·ª•c `data/`

**Options:**
- `--clear`: X√≥a collection c≈© tr∆∞·ªõc khi th√™m
- `--force`: Force reprocess t·∫•t c·∫£ PDFs 
- `--check`: Ch·ªâ ki·ªÉm tra prerequisites
- `--help`: Hi·ªÉn th·ªã tr·ª£ gi√∫p

**V√≠ d·ª•:**

```bash
# N·∫°p t·∫•t c·∫£ PDF t·ª´ data/ (m·∫∑c ƒë·ªãnh)
python ingest_data.py

# N·∫°p v·ªõi x√≥a d·ªØ li·ªáu c≈©
python ingest_data.py --clear

# N·∫°p t·ª´ path c·ª• th·ªÉ
python ingest_data.py specific_folder/

# Ki·ªÉm tra h·ªá th·ªëng
python ingest_data.py --check
```

### ü§ñ Main Application

```bash
python main.py [mode]
```

**Modes:**
- `setup`: H∆∞·ªõng d·∫´n setup l·∫ßn ƒë·∫ßu (khuy·∫øn ngh·ªã)
- `demo`: Demo chatbot v·ªõi c√¢u h·ªèi m·∫´u
- `interactive`: Ch·∫ø ƒë·ªô chat t∆∞∆°ng t√°c
- `batch`: Demo x·ª≠ l√Ω batch queries
- `check`: Ki·ªÉm tra tr·∫°ng th√°i d·ªØ li·ªáu
- `info`: Hi·ªÉn th·ªã th√¥ng tin h·ªá th·ªëng

## üíª S·ª≠ d·ª•ng trong Code

### 1. T·∫°o Chatbot Instance

```python
from chatbot import PDFChatbot, create_chatbot

# C√°ch 1: T·∫°o instance m·ªõi
chatbot = PDFChatbot()

# C√°ch 2: S·ª≠ d·ª•ng factory function
chatbot = create_chatbot()

# C√°ch 3: Singleton instance
from chatbot import get_chatbot
chatbot = get_chatbot()
```

### 2. S·ª≠ d·ª•ng Invoke Method

```python
# C√¢u h·ªèi ƒë∆°n gi·∫£n
result = chatbot.invoke("T√†i li·ªáu n√†y n√≥i v·ªÅ g√¨?")
print(result["answer"])

# V·ªõi tham s·ªë t√πy ch·ªânh
result = chatbot.invoke(
    "Ph∆∞∆°ng ph√°p nghi√™n c·ª©u l√† g√¨?",
    top_k=10,
    similarity_threshold=0.6,
    verbose=True
)

# Ki·ªÉm tra k·∫øt qu·∫£
if result["status"] == "success":
    print(f"Tr·∫£ l·ªùi: {result['answer']}")
    print(f"Ngu·ªìn: {result['sources']}")
    print(f"Docs li√™n quan: {result['relevant_docs_count']}")
else:
    print(f"L·ªói: {result['error']}")
```

### 3. Batch Processing

```python
questions = [
    "V·∫•n ƒë·ªÅ ch√≠nh l√† g√¨?",
    "Ph∆∞∆°ng ph√°p ƒë∆∞·ª£c s·ª≠ d·ª•ng?",
    "K·∫øt lu·∫≠n quan tr·ªçng?"
]

results = chatbot.batch_invoke(questions, verbose=True)

for q, result in zip(questions, results):
    print(f"Q: {q}")
    print(f"A: {result['answer']}")
    print("-" * 50)
```

### 4. Health Check v√† Monitoring

```python
# Ki·ªÉm tra s·ª©c kh·ªèe
health = chatbot.health_check()
print(f"Status: {health['status']}")

# Th·ªëng k√™ collection
stats = chatbot.get_collection_stats()
print(f"Vectors: {stats['vectors_count']}")

# Metadata t·ª´ response
result = chatbot.invoke("test question")
metadata = result["metadata"]
print(f"Model: {metadata['llm_model']}")
print(f"Embedding: {metadata['embedding_model']}")
```

## üîÑ Workflow trong Production

### 1. Setup l·∫ßn ƒë·∫ßu

```bash
# 1. C√†i ƒë·∫∑t v√† c·∫•u h√¨nh
pip install -r requirements.txt
docker-compose up -d
export GOOGLE_API_KEY="your_key"

# 2. N·∫°p d·ªØ li·ªáu ban ƒë·∫ßu
python ingest_data.py documents/ --clear

# 3. Test chatbot
python main.py check
python main.py demo
```

### 2. C·∫≠p nh·∫≠t d·ªØ li·ªáu

```bash
# Khi c√≥ PDF m·ªõi, ch·ªâ c·∫ßn ch·∫°y ingest
python ingest_data.py new_documents/

# Ho·∫∑c thay th·∫ø ho√†n to√†n
python ingest_data.py all_documents/ --clear
```

### 3. S·ª≠ d·ª•ng h√†ng ng√†y

```python
# Trong application
from chatbot import get_chatbot

chatbot = get_chatbot()  # Singleton, t√°i s·ª≠ d·ª•ng

# X·ª≠ l√Ω user query
user_question = "..."
response = chatbot.invoke(user_question)
```

## üéØ Use Cases

### 1. Web API

```python
from fastapi import FastAPI
from chatbot import get_chatbot

app = FastAPI()
chatbot = get_chatbot()

@app.post("/chat")
async def chat(query: str):
    result = chatbot.invoke(query)
    return {
        "answer": result["answer"],
        "sources": result["sources"],
        "status": result["status"]
    }
```

### 2. Command Line Tool

```python
import sys
from chatbot import create_chatbot

def cli_chat():
    chatbot = create_chatbot()
    
    while True:
        query = input("Question: ")
        if query.lower() == 'exit':
            break
            
        result = chatbot.invoke(query)
        print(f"Answer: {result['answer']}")

if __name__ == "__main__":
    cli_chat()
```

### 3. Jupyter Notebook

```python
# Cell 1: Setup
from chatbot import create_chatbot
chatbot = create_chatbot()

# Cell 2: Test
result = chatbot.invoke("T√≥m t·∫Øt t√†i li·ªáu n√†y")
display(result["answer"])

# Cell 3: Batch analysis
questions = ["Q1", "Q2", "Q3"]
results = chatbot.batch_invoke(questions)
```

## ‚öôÔ∏è Configuration

### Runtime Configuration

```python
from config import Config

# T√πy ch·ªânh runtime
Config.TOP_K_DOCUMENTS = 10
Config.SIMILARITY_THRESHOLD = 0.6
Config.GEMINI_TEMPERATURE = 0.2

# S·ª≠ d·ª•ng v·ªõi chatbot
result = chatbot.invoke("question", top_k=15)
```

### Environment Variables

```bash
export GOOGLE_API_KEY="your_key"
export GEMINI_MODEL="gemini-1.5-pro"
export QDRANT_URL="http://localhost:6333"
export COLLECTION_NAME="my_docs"
export TOP_K_DOCUMENTS="10"
export SIMILARITY_THRESHOLD="0.7"
```

## üö® Troubleshooting

### 1. L·ªói Collection r·ªóng

```bash
# Ki·ªÉm tra
python ingest_data.py --check

# N·∫°p d·ªØ li·ªáu
python ingest_data.py documents/
```

### 2. L·ªói Qdrant connection

```bash
# Ki·ªÉm tra Qdrant
curl http://localhost:6333/health
docker-compose ps

# Restart n·∫øu c·∫ßn
docker-compose restart
```

### 3. L·ªói Google API

```python
# Test API key
from chatbot import create_chatbot
chatbot = create_chatbot()
health = chatbot.health_check()
print(health)
```

## üìä Monitoring

### Log Output

```
ü§ñ Kh·ªüi t·∫°o PDF Chatbot...
ü§ñ ƒêang kh·ªüi t·∫°o Gemini model: gemini-1.5-flash
üìä Collection ready: 1500 vectors
‚úÖ Chatbot ƒë√£ s·∫µn s√†ng!
```

### Performance Metrics

```python
import time

start = time.time()
result = chatbot.invoke("complex question")
end = time.time()

print(f"Response time: {end - start:.2f}s")
print(f"Docs retrieved: {result['total_retrieved_count']}")
print(f"Docs relevant: {result['relevant_docs_count']}")
```

---

üí° **Tips:**
- Ch·∫°y data ingestion khi c√≥ d·ªØ li·ªáu m·ªõi
- S·ª≠ d·ª•ng singleton pattern cho chatbot trong production
- Monitor response time v√† accuracy
- Backup collection before major updates 