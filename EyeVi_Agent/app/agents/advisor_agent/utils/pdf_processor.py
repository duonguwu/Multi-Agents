import PyPDF2
from typing import List, Dict
from langchain.text_splitter import RecursiveCharacterTextSplitter, TokenTextSplitter
from langchain.docstore.document import Document
from config import Config
import re

class PDFProcessor:
    def __init__(self):
        """
        Kh·ªüi t·∫°o PDF processor v·ªõi chunking strategy t·ªëi ∆∞u cho ti·∫øng Vi·ªát
        """
        print(f"üîß Kh·ªüi t·∫°o PDF Processor...")
        print(f"   Chunk size: {Config.CHUNK_SIZE}")
        print(f"   Chunk overlap: {Config.CHUNK_OVERLAP}")
        print(f"   Strategy: {Config.CHUNK_STRATEGY}")
        
        self._init_text_splitter()
    
    def _init_text_splitter(self):
        """
        Kh·ªüi t·∫°o text splitter t·ªëi ∆∞u cho ti·∫øng Vi·ªát
        """
        if Config.CHUNK_STRATEGY == "recursive":
            # T·ªëi ∆∞u cho ti·∫øng Vi·ªát - separators t√πy ch·ªânh
            vietnamese_separators = [
                "\n\n",  # Paragraph breaks
                "\n",    # Line breaks  
                ". ",    # Sentence ends
                "! ",    # Exclamation
                "? ",    # Question
                "; ",    # Semicolon
                ", ",    # Comma
                " ",     # Space
                ""       # Character level
            ]
            
            self.text_splitter = RecursiveCharacterTextSplitter(
                separators=vietnamese_separators,
                chunk_size=Config.CHUNK_SIZE,
                chunk_overlap=Config.CHUNK_OVERLAP,
                length_function=len,
                is_separator_regex=False,
            )
        elif Config.CHUNK_STRATEGY == "semantic":
            # Semantic chunking - group by meaning
            self.text_splitter = RecursiveCharacterTextSplitter(
                chunk_size=Config.CHUNK_SIZE,
                chunk_overlap=Config.CHUNK_OVERLAP,
                separators=["\n\n", "\n", ". ", "! ", "? "],
                length_function=len,
            )
        elif Config.CHUNK_STRATEGY == "token":
            # Token-based chunking
            self.text_splitter = TokenTextSplitter(
                chunk_size=Config.CHUNK_SIZE // 4,  # ~4 chars per token
                chunk_overlap=Config.CHUNK_OVERLAP // 4,
            )
        else:  # fixed
            self.text_splitter = RecursiveCharacterTextSplitter(
                chunk_size=Config.CHUNK_SIZE,
                chunk_overlap=Config.CHUNK_OVERLAP,
            )
    
    def clean_vietnamese_text(self, text: str) -> str:
        """
        L√†m s·∫°ch text ti·∫øng Vi·ªát
        """
        # Remove extra whitespaces
        text = re.sub(r'\s+', ' ', text)
        
        # Remove weird characters but keep Vietnamese
        text = re.sub(r'[^\w\s√†√°√¢√£√®√©√™√¨√≠√Æ√Ø√≤√≥√¥√µ√∂√π√∫√ª√º·ª≥√Ωƒëƒê.,!?;:\-\(\)\[\]\"\']+', ' ', text)
        
        # Remove multiple punctuation
        text = re.sub(r'([.!?]){2,}', r'\1', text)
        
        # Clean up spaces around punctuation
        text = re.sub(r'\s*([.!?;,:])\s*', r'\1 ', text)
        
        return text.strip()
    
    def extract_text_from_pdf(self, pdf_path: str) -> str:
        """
        Extract text t·ª´ PDF v·ªõi error handling
        """
        try:
            with open(pdf_path, 'rb') as file:
                pdf_reader = PyPDF2.PdfReader(file)
                text = ""
                
                for page_num, page in enumerate(pdf_reader.pages):
                    try:
                        page_text = page.extract_text()
                        if page_text:
                            # Clean Vietnamese text
                            cleaned_text = self.clean_vietnamese_text(page_text)
                            text += f"\n--- Trang {page_num + 1} ---\n{cleaned_text}\n"
                    except Exception as e:
                        print(f"   ‚ö†Ô∏è  L·ªói ƒë·ªçc trang {page_num + 1}: {e}")
                        continue
                
                return text
                
        except Exception as e:
            raise Exception(f"Kh√¥ng th·ªÉ ƒë·ªçc PDF {pdf_path}: {e}")
    
    def create_overlapping_chunks(self, texts: List[str], metadata: Dict) -> List[Dict]:
        """
        T·∫°o chunks v·ªõi overlap th√¥ng minh cho context t·ªët h∆°n
        """
        chunks = []
        
        if Config.OVERLAP_METHOD == "sliding":
            # Sliding window overlap
            for i, text in enumerate(texts):
                chunk = {
                    "content": text,
                    "source": metadata["source"],
                    "chunk_id": i,
                    "total_chunks": len(texts),
                    "metadata": {
                        **metadata,
                        "chunk_method": "sliding_overlap",
                        "overlap_size": Config.CHUNK_OVERLAP
                    }
                }
                chunks.append(chunk)
                
        elif Config.OVERLAP_METHOD == "sentence":
            # Sentence-aware overlap
            for i, text in enumerate(texts):
                # Th√™m context t·ª´ chunk tr∆∞·ªõc v√† sau
                enhanced_text = text
                
                if i > 0 and len(texts[i-1]) > 0:
                    # L·∫•y 1-2 c√¢u cu·ªëi t·ª´ chunk tr∆∞·ªõc
                    prev_sentences = texts[i-1].split('. ')[-2:]
                    enhanced_text = '. '.join(prev_sentences) + '. ' + enhanced_text
                
                if i < len(texts) - 1 and len(texts[i+1]) > 0:
                    # L·∫•y 1-2 c√¢u ƒë·∫ßu t·ª´ chunk sau
                    next_sentences = texts[i+1].split('. ')[:2]
                    enhanced_text = enhanced_text + '. ' + '. '.join(next_sentences)
                
                chunk = {
                    "content": enhanced_text,
                    "source": metadata["source"],
                    "chunk_id": i,
                    "total_chunks": len(texts),
                    "metadata": {
                        **metadata,
                        "chunk_method": "sentence_overlap",
                        "enhanced": True
                    }
                }
                chunks.append(chunk)
                
        else:  # paragraph
            # Paragraph-aware overlap
            for i, text in enumerate(texts):
                chunk = {
                    "content": text,
                    "source": metadata["source"], 
                    "chunk_id": i,
                    "total_chunks": len(texts),
                    "metadata": {
                        **metadata,
                        "chunk_method": "paragraph_overlap"
                    }
                }
                chunks.append(chunk)
        
        return chunks
    
    def process_pdf(self, pdf_path: str) -> List[Dict]:
        """
        X·ª≠ l√Ω PDF th√†nh chunks v·ªõi metadata chi ti·∫øt
        """
        try:
            print(f"   üìñ Extracting text t·ª´ PDF...")
            
            # Extract text
            full_text = self.extract_text_from_pdf(pdf_path)
            
            if not full_text.strip():
                print(f"   ‚ùå PDF r·ªóng ho·∫∑c kh√¥ng ƒë·ªçc ƒë∆∞·ª£c text")
                return []
            
            print(f"   üìù Text length: {len(full_text)} chars")
            
            # Split into chunks
            print(f"   ‚úÇÔ∏è  Chunking v·ªõi strategy: {Config.CHUNK_STRATEGY}")
            texts = self.text_splitter.split_text(full_text)
            
            # Create metadata
            import os
            metadata = {
                "source": os.path.basename(pdf_path),
                "file_path": pdf_path,
                "file_size": os.path.getsize(pdf_path),
                "chunk_size": Config.CHUNK_SIZE,
                "chunk_overlap": Config.CHUNK_OVERLAP,
                "chunk_strategy": Config.CHUNK_STRATEGY,
                "overlap_method": Config.OVERLAP_METHOD,
                "total_chars": len(full_text)
            }
            
            # Create chunks with overlap
            chunks = self.create_overlapping_chunks(texts, metadata)
            
            print(f"   ‚úÖ T·∫°o ƒë∆∞·ª£c {len(chunks)} chunks")
            
            # Quality check
            avg_chunk_size = sum(len(chunk["content"]) for chunk in chunks) / len(chunks)
            print(f"   üìä Average chunk size: {avg_chunk_size:.0f} chars")
            
            return chunks
            
        except Exception as e:
            print(f"   ‚ùå L·ªói x·ª≠ l√Ω PDF: {e}")
            return []
    
    def get_chunk_statistics(self, chunks: List[Dict]) -> Dict:
        """
        Th·ªëng k√™ v·ªÅ chunks ƒë·ªÉ tune parameters
        """
        if not chunks:
            return {}
        
        chunk_sizes = [len(chunk["content"]) for chunk in chunks]
        
        stats = {
            "total_chunks": len(chunks),
            "avg_chunk_size": sum(chunk_sizes) / len(chunk_sizes),
            "min_chunk_size": min(chunk_sizes),
            "max_chunk_size": max(chunk_sizes),
            "chunk_size_std": (sum((x - sum(chunk_sizes)/len(chunk_sizes))**2 for x in chunk_sizes) / len(chunk_sizes))**0.5,
            "strategy_used": Config.CHUNK_STRATEGY,
            "overlap_used": Config.CHUNK_OVERLAP
        }
        
        return stats 