Tài liệu Workflow: Hệ thống Hỏi-Đáp Tài liệu PDF sử dụng LangGraph, RAG và Qdrant1. Tổng QuanTài liệu này mô tả luồng công việc (workflow) của một hệ thống thông minh có khả năng hiểu câu hỏi của người dùng và trả lời dựa trên nội dung của các tài liệu PDF được cung cấp. Hệ thống này tận dụng sức mạnh của LangGraph để điều phối các tác vụ, kỹ thuật RAG để kết hợp truy xuất thông tin với khả năng sinh văn bản, và Qdrant làm cơ sở dữ liệu vector để lưu trữ và tìm kiếm hiệu quả.Các thành phần chính:LangGraph: Một thư viện giúp xây dựng các ứng dụng dựa trên LLM (Mô hình Ngôn ngữ Lớn) một cách linh hoạt dưới dạng đồ thị (graph), quản lý trạng thái và luồng xử lý phức tạp.RAG (Retrieval Augmented Generation): Một kiến trúc trong đó hệ thống đầu tiên truy xuất (retrieve) các thông tin liên quan từ một kho kiến thức (ở đây là các tài liệu PDF đã xử lý), sau đó sử dụng thông tin này để tăng cường (augment) quá trình sinh (generate) câu trả lời của LLM.Qdrant: Một cơ sở dữ liệu vector được tối ưu hóa cho việc lưu trữ và tìm kiếm các vector embedding (nhúng) – là các biểu diễn số học của dữ liệu văn bản.Mô hình Embedding: Công cụ chuyển đổi văn bản (cả nội dung tài liệu và câu hỏi của người dùng) thành các vector số học, giúp máy tính hiểu được ngữ nghĩa.LLM (Large Language Model): Mô hình ngôn ngữ lớn có khả năng hiểu ngôn ngữ tự nhiên và tạo ra các câu trả lời mạch lạc, có ý nghĩa.2. Giai Đoạn 1: Chuẩn Bị và Nạp Dữ Liệu (Thực hiện một lần hoặc khi cập nhật tài liệu)Giai đoạn này là bước tiền xử lý, chuẩn bị "kiến thức" cho agent từ các file PDF.Bước 2.1: Tải và Phân Tách Tài Liệu PDF (Load & Split)Hành động: Hệ thống đọc nội dung từ các file PDF được chỉ định.Chi tiết: Văn bản thô được trích xuất từ mỗi trang của PDF. Sau đó, toàn bộ văn bản này được chia thành các đoạn (chunks) nhỏ hơn, có thể quản lý được. Việc phân đoạn này rất quan trọng để đảm bảo rằng mỗi chunk chứa đủ ngữ cảnh nhưng không quá dài, tối ưu cho việc embedding và truy xuất. Kỹ thuật phân đoạn có thể bao gồm việc xác định kích thước chunk và mức độ chồng lấn (overlap) giữa các chunk để tránh mất thông tin ở ranh giới.Bước 2.2: Tạo Vector Embedding cho Tài Liệu (Document Embedding)Hành động: Mỗi đoạn văn bản (chunk) đã được tách ra ở bước trước sẽ được đưa qua một mô hình embedding.Chi tiết: Mô hình embedding chuyển đổi mỗi chunk thành một vector số học (một dãy số). Vector này nắm bắt ý nghĩa ngữ nghĩa của đoạn văn bản đó. Việc chọn mô hình embedding phù hợp (ví dụ: hỗ trợ tốt tiếng Việt, phù hợp với loại nội dung tài liệu) là rất quan trọng.Bước 2.3: Lưu Trữ Vector vào Qdrant (Indexing in Qdrant)Hành động: Các vector embedding được tạo ra (cùng với nội dung văn bản gốc của chunk tương ứng và có thể cả metadata như tên file, số trang) được lưu trữ vào một "collection" trong cơ sở dữ liệu Qdrant.Chi tiết: Qdrant sẽ lập chỉ mục (index) các vector này, cho phép tìm kiếm nhanh chóng các vector tương tự nhau dựa trên khoảng cách hình học (ví dụ: cosine similarity).3. Giai Đoạn 2: Xử Lý Truy Vấn Hỏi-Đáp (Điều phối bởi LangGraph - Thực hiện mỗi khi người dùng đặt câu hỏi)Đây là luồng xử lý chính khi người dùng tương tác với hệ thống. LangGraph sẽ quản lý trạng thái và điều hướng qua các bước sau:Bước 3.1: Tiếp Nhận và Xử Lý Câu Hỏi Người Dùng (User Query Reception & Processing)Hành động: Agent nhận câu hỏi từ người dùng.Chi tiết: Câu hỏi của người dùng (dưới dạng văn bản) được đưa qua cùng một mô hình embedding đã sử dụng ở Giai đoạn 1 (Bước 2.2) để tạo ra một vector câu hỏi.Bước 3.2: Truy Xuất Thông Tin Liên Quan từ Qdrant (Relevant Information Retrieval)Hành động: Sử dụng vector câu hỏi để tìm kiếm trong Qdrant.Chi tiết: Hệ thống gửi vector câu hỏi đến Qdrant. Qdrant sẽ so sánh vector này với tất cả các vector tài liệu đã được lưu trữ trong collection và trả về một danh sách các chunk tài liệu có vector gần nhất (tức là, tương đồng nhất về mặt ngữ nghĩa) với câu hỏi. Số lượng chunk trả về có thể được cấu hình (ví dụ: top 3, top 5 chunk liên quan nhất).Bước 3.3: Đánh Giá và Lọc Kết Quả Truy Xuất (Retrieved Results Grading & Filtering)Hành động: Các chunk tài liệu truy xuất được từ Qdrant sẽ được đánh giá mức độ liên quan thực sự với câu hỏi.Chi tiết: Đây là một bước quan trọng để đảm bảo chất lượng. Không phải tất cả các chunk được Qdrant trả về đều hữu ích 100%. Việc đánh giá có thể dựa trên:Ngưỡng điểm tương đồng do Qdrant cung cấp.Sử dụng một LLM nhỏ hơn để "chấm điểm" độ liên quan của mỗi chunk với câu hỏi.Kiểm tra sự xuất hiện của các từ khóa chính từ câu hỏi trong các chunk.Các chunk không đạt yêu cầu sẽ bị loại bỏ.Bước 3.4: Tổng Hợp Ngữ Cảnh (Context Aggregation)Hành động: Nội dung của các chunk tài liệu đã được lọc và đánh giá là liên quan sẽ được kết hợp lại.Chi tiết: Các chunk này được ghép lại thành một đoạn văn bản ngữ cảnh (context) duy nhất. Đây chính là "kiến thức" được chắt lọc từ PDF mà LLM sẽ sử dụng để trả lời.Bước 3.5: Tạo Câu Trả Lời với LLM (Answer Generation with LLM)Hành động: Hệ thống xây dựng một prompt (câu lệnh đầu vào) hoàn chỉnh và gửi đến LLM.Chi tiết: Prompt này thường bao gồm:Chỉ dẫn (Instructions): Yêu cầu LLM trả lời câu hỏi dựa trên ngữ cảnh được cung cấp, không tự ý suy diễn thông tin không có trong ngữ cảnh, và có thể yêu cầu định dạng trả lời cụ thể.Ngữ cảnh (Context): Đoạn văn bản tổng hợp từ Bước 3.4.Câu hỏi (Question): Câu hỏi gốc của người dùng.LLM sẽ xử lý prompt này và tạo ra câu trả lời.Bước 3.6: Trả Kết Quả cho Người Dùng (Returning the Answer)Hành động: Câu trả lời do LLM tạo ra được gửi lại cho người dùng.Chi tiết: Đây là đầu ra cuối cùng của workflow cho một truy vấn cụ thể.Luồng Điều Kiện và Xử Lý Lỗi (Conditional Flows & Error Handling):LangGraph cho phép định nghĩa các luồng rẽ nhánh. Ví dụ:Nếu không tìm thấy tài liệu liên quan (sau Bước 3.3): Agent có thể được cấu hình để thông báo cho người dùng rằng không tìm thấy thông tin trong tài liệu, thay vì cố gắng trả lời mà không có cơ sở.Xử lý lỗi: Nếu có lỗi xảy ra ở bất kỳ bước nào (ví dụ: lỗi kết nối Qdrant, lỗi API của LLM), LangGraph có thể điều hướng đến một node xử lý lỗi để thông báo một cách thân thiện cho người dùng.4. Kết LuậnWorkflow này, được điều phối bởi LangGraph, cung cấp một giải pháp mạnh mẽ và linh hoạt để xây dựng các agent hỏi-đáp dựa trên tài liệu PDF. Bằng cách tách biệt các giai đoạn chuẩn bị dữ liệu và xử lý truy vấn, cùng với việc chia nhỏ quá trình xử lý thành các node có thể quản lý được, hệ thống trở nên dễ phát triển, bảo trì và mở rộng. Kỹ thuật RAG đảm bảo rằng câu trả lời của LLM được neo vào thông tin thực tế từ tài liệu, giảm thiểu việc "bịa đặt" thông tin.